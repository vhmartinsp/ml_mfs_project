# -*- coding: utf-8 -*-
"""mfs_ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FiWBSY5f_4gT-dM44rxmbi6LdjuZ9hGi

# **Tópicos**

<ol type="1">
  <li>Regressão;</li>
  <li>Dados;</li>
  <li>Treino;</li>
  <li>Avaliação;</li>
  <li>Predição.</li>
</ol>

---

# **Projeto**

## 0\. Abordagens estatísticas

*   **Descritiva**: foco no passado para entender o **presente**.
*   <font color='red'>**Preditiva**</font>: foca no passado para inferir o **futuro**.

## 1\. Regressão

### **1.1. Problemática**

> Dado a **designação, alocação de recursos, modelo home office ou não**, qual deve ser a taxa de **fadiga**?

Queremos uma equação matemática que represente esta relação. Uma possível equação seria a equação linear de primero grau:

> $y = f(x) = \textbf{a}x + \textbf{b}$

O número $\textbf{a}$ é chamado de coeficiente angular e controla a inclinação da reta, já o número $\textbf{b}$ é chamado de coeficiente linear e indica o deslocamento horizontal da reta. A idéia é predizer a pontuação de fadiga mental da pessoa colaboradora deve ter dado a alocação de recursos, ou seja:

> $f(Mental Fatigue Score) = \textbf f(Designacao) + \textbf f(Alocacao de Recursos) + \ \textbf{b}$

Qual o melhor valor de $\textbf{a}$ e $\textbf{b}$ para esse conjunto de dados?

### **1.2. Regressão Linear**
A regressão preve alguma variável numérica, contrasta com a classificação (ambos ficam dentro do supervisionado)

A regressão linear é um abordagem estatística que busca encontrar a relaçao entre um atributo alvo $y$ (variável resposta) e um conjunto de atributos preditores $x_i$ através de uma linha reta (em uma ou mais dimensões), relação essa preferencialmente **causal**. De maneira geral, busca encontrar $\textbf{a}_i$ e $\textbf{b}$ tal que:

> $y = f(x_i) = (\sum_{i=1}^{n} \textbf{a}_ix_i) + \textbf{b}$

Para apenas uma dimensão ou um atributo, temos:

> $y = f(x_1) = \textbf{a}_1x_1 + \textbf{b}$

Como temos dois atributos, temos:

Mental Fatigue Score=a1 × Designation + a2 × Resource Allocation + b

- **Exemplo**: Pontuação de Fadiga Mental como função da Alocação de Recursos.

> $y = f(x1, x2) =  {a1x1} + {a2x2} + \textbf{b}$

> $Mental Fatigue Score = f(Designation, Resource Allocation) = \textbf{a1} (Delegation) + {a2}(Resource Allocation) + \textbf{b}$

Através do **treino** do modelo, encontra-se os valores de $\textbf{a}$ e $\textbf{b}$ que melhor se ajustam a um conjunto de dados.

Os erros são o preço da generalização

### **1.3. Pacote Scikit-Learn**

Pacote Python para ciência de dados e *machine learning*. A documentação pode ser encontrada neste [link](https://scikit-learn.org/stable/). Possuí diversos modelos para aprendizado supervisionado, não supervisionado, etc. além de métodos auxiliares. Para regressão linear, temos:
"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()

"""## 2\. Dados

### **2.1. Pré-processamento**
"""

!wget -q "https://raw.githubusercontent.com/vhmartinsp/datasets/main/train%20-%20train.csv?token=GHSAT0AAAAAACLMEG44XDHWNO5V7BPEDMIMZMUM5JA" -O train.csv

import numpy as np
import pandas as pd
import seaborn as sns

train_df = pd.read_csv("train.csv")

"""Vamos conhecer um pouco melhor o conjunto de dados."""

train_df.head()

train_df.describe().T

train_df

train = train_df[['Designation','Resource Allocation', 'Mental Fatigue Score']]
train.head()

def preprocess_data(df, is_train=True):
    if is_train:
        data_train = train.dropna()
    data_train['Designation'] = (train['Designation'] - train['Designation'].mean()) / train['Designation'].std()
    data_train['Resource Allocation'] = (train['Resource Allocation'] - train['Resource Allocation'].mean()) / train['Resource Allocation'].std()
    return data_train

data_train = preprocess_data(train)

data_train

"""Logo, iremos processar e verificar se nossos dados de teste precisam de tratamento"""

!wget -q "https://raw.githubusercontent.com/vhmartinsp/datasets/main/test.csv?token=GHSAT0AAAAAACLMEG44PZHET6U7JHJ53LM4ZMUM55A" -O test.csv

test_df = pd.read_csv("test.csv")

test_df.head()

test = test_df[['Designation','Resource Allocation', 'Mental Fatigue Score']]
test.head()

def preprocess_data(df, is_test=True):
    if is_test:
        data_test = test.dropna()
    data_test['Designation'] = (test['Designation'] - test['Designation'].mean()) / test['Designation'].std()
    data_test['Resource Allocation'] = (test['Resource Allocation'] - test['Resource Allocation'].mean()) / test['Resource Allocation'].std()
    return data_test

data_test = preprocess_data(test)

data_test.info()

data_test.describe().T

data_test

"""O resultado do pré-processamento nos trás um dado limpo e pronto para ser utilizado no treino do modelo.

### **2.2. Treino / Teste**

De maneira geral, um modelo de aprendizagem supervisionada precisa ser treinado com um conjunto de dados e avaliado com outro, assim conseguimos enter um pouco melhor a capacidade do modelo em **generalizar** as predições com dados não visto, que é a situação real em que será utilizado. Para tanto, dividimos nossa base de dados em duas: uma maior de **treino** e uma menor de **testes**.
"""

from sklearn.model_selection import train_test_split

predictors_train, predictors_test, target_train, target_test = train_test_split(
    data_test.drop(['Mental Fatigue Score'], axis=1),
    data_test['Mental Fatigue Score'],
    test_size=0.2,
    random_state=42
)

""" - **Variáveis preditoras (predictors)**"""

predictors_train.head()

predictors_train.shape

predictors_test.head()

predictors_test.shape

""" - **Variável resposta (target)**"""

target_train.head()

target_train.shape

target_test.head()

target_test.shape

"""## 3\. Treino

O treino de modelos de aprendizagem supervisionada consiste na etapa de calculo dos coeficientes do modelo baseado na associação da variável resposta com os variáveis preditoras através do uso de um ou mais algoritmos. No caso da regressão linear, estamo interessados em definir os valores de $\textbf{a}_i$ e $\textbf{b}$:

> $y = f(x_i) = (\sum_{i=1}^{n} \textbf{a}_ix_i) + \textbf{b}$

### **3.1. Algoritmo**

O treino de um modelo de regressão linear é feito através do uso do método de gradiente (explicação neste [link](https://en.wikipedia.org/wiki/Gradient_descent)). A explicação do algoritmo foge do escopo desse curso mas a idéia é que busca-se minimizar a diferença entre os pontos e a reta definida por $\textbf{a}_i$ e $\textbf{b}$, ou seja, encontrar os valores de $\textbf{a}_i$ e $\textbf{b}$ que define a reta que esta mais "perto" de todos os pontos da base de dados de treino.
"""

model.__dict__

# Função para treinar o modelo
def train_model(predictors, target):
    model = LinearRegression()
    model.fit(predictors, target)
    return model

model = train_model(predictors_train, target_train)

a = model.coef_
print(a)

b = model.intercept_
print(b)

"""Logo, temos:

> $y = f(x1, x2) = \textbf{a1x1} + {a2x2} + + \textbf{b}$

> $f(Mental Fatigue Score) = \textbf {a} (a * Designacao) + \textbf {a} (a * Alocacao de Recursos) + \textbf {b}$

Com o modelo treinado, estamos prontos para fazer predições.
"""

data_test.head(1)

designacao = -0.154707
alocacao_recurso = 0.26454


pontucao_fadiga_mental = (a * designacao) + (a * alocacao_recurso) + b

print(pontucao_fadiga_mental)

alocacao_recurso = np.array([-0.154707, 0.26454])
pontuacao_fadiga_mental = model.predict(alocacao_recurso.reshape(1, -1))

print(pontucao_fadiga_mental)

"""## 4\. Avaliação

Para enter o poder preditivo do modelo de aprendizagem supervisionada, precisamos avaliar sua capacidade de generalização, ou seja, avalivar as predições em dados "não vistos" na etapa de treino. Comparamos então as predições com os dados reais através de uma métrica.

- **Salário predito**
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

def evaluate_model(model, predictors_test, target_test):
    target_predicted = model.predict(predictors_test)
    rmse = np.sqrt(mean_squared_error(target_test, target_predicted))
    print(f"RMSE: {rmse}")

    prediction_data = pd.DataFrame({
        'Resource Allocation': predictors_test['Resource Allocation'],
        'Mental Fatigue Score': target_predicted
    })

    with sns.axes_style('whitegrid'):
        sns.scatterplot(data=prediction_data, x='Resource Allocation', y='Mental Fatigue Score', color='blue', label='Predicted')
        sns.scatterplot(data=prediction_data, x='Resource Allocation', y=target_test, color='red', label='Actual')
        plt.legend()
        plt.show()

def make_prediction(model, example):
    return model.predict(example.reshape(1, -1))

target_predicted = model.predict(predictors_test)

target_predicted[0:5]

target_predicted.shape

target_test[0:5]

target_test.shape

"""### **4.1. RMSE**

Do inglês *root mean square error* ou raíz quadrada do erro quadrático médio, o RMSE mede a diferença média absoluta entre os valores preditos com os valores reais. O resultado pode ser interpretado com uma faixa de valor em que a predição varia do valor real, portanto, quando menor, melhor. Contudo, a definição de "menor" é particular para cada variável resposta devido a diferenças de escala.

O RMSE é definido como:

> $RMSE(y,\hat{y}) = \sqrt{\frac{\sum_{i=1}^{n} (y_i-\hat{y}_i)^{2}}{n}}$
"""

from sklearn.metrics import mean_squared_error

rmse = np.sqrt(mean_squared_error(target_test, target_predicted))
print(rmse)

"""Para facilitar sua interpretação, vamos colocar numa gráfico os valores de reais de teste e os valores preditos."""

test_data = pd.concat([predictors_test, pd.DataFrame(target_test, columns=['Mental Fatigue Score'])], axis=1).reset_index(drop=True)
test_data['predicted'] = False

test_data.head()

prediction_data = pd.concat([predictors_test.reset_index(drop=True), pd.DataFrame(target_predicted, columns=['Mental Fatigue Score'])], axis=1).reset_index(drop=True)
prediction_data['predicted'] = True

prediction_data.tail()

prediction = pd.concat([test_data, prediction_data]).reset_index(drop=True)

with sns.axes_style('whitegrid'):

  sns.scatterplot(data=prediction, x='Resource Allocation', y='Mental Fatigue Score', hue='predicted')

"""Agora iremos repetir o processo para o DataFrame de **Teste**"""

data_teste = data_test[['Designation', 'Resource Allocation']]
data_teste.head()

data_teste

data_teste.head()

"""

* Treino

"""

model_v2 = model.fit(predictors_train, target_train)
model_v2.__dict__

a = model_v2.coef_
print(a)

b = model_v2.intercept_
print(b)

"""**Teste**"""

target_predicted = model_v2.predict(predictors_test)

rmse_v2 = np.sqrt(mean_squared_error(target_test, target_predicted))
print(rmse_v2)

test_data = pd.concat([predictors_test, pd.DataFrame(target_test, columns=['Mental Fatigue Score'])], axis=1).reset_index(drop=True)
test_data['predicted'] = False

prediction_data = pd.concat([predictors_test.reset_index(drop=True), pd.DataFrame(target_predicted, columns=['Mental Fatigue Score'])], axis=1).reset_index(drop=True)
prediction_data['predicted'] = True

prediction_v2 = pd.concat([test_data, prediction_data]).reset_index(drop=True)

with sns.axes_style('whitegrid'):

  sns.scatterplot(data=prediction, x='Designation', y='Mental Fatigue Score', hue='predicted')

with sns.axes_style('whitegrid'):

  sns.scatterplot(data=prediction_v2, x='Resource Allocation', y='Mental Fatigue Score', hue='predicted')

"""## 5\. Predição

Com o modelo treinado, avaliado e selecionado, podemos utiliza-lo para resolver os problemas reais que motivaram sua construção, para tanto para criar um exemplo pré-processado e utilizar o modelo para realizar a predição.

> **Atenção**: O exemplo precisa seguir o mesmo pré-processamento realizado na construção do modelo.

Primeiro, explorarei as correlações entre as variáveis preditoras e a variável resposta
"""

designation_array = np.array(data_test['Designation'].to_list())
resource_alocation_array = np.array(data_test['Resource Allocation'].to_list())
mfs_array= np.array (data_test['Mental Fatigue Score'].to_list())

designation_array

np.corrcoef(resource_alocation_array, mfs_array)

data_test.head(3)

pessoa_colaboradora = np.array([-1.0400, -1.202022])

pontuacao_fadiga_mental = model_v2.predict(pessoa_colaboradora.reshape(1, -1))
print(pontuacao_fadiga_mental)